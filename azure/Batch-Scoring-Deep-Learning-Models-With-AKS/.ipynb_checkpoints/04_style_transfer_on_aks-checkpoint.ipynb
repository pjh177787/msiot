{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Neural Style Transfer on AKS\n",
    "\n",
    "Now that the AKS cluster is up, we need to deploy our __flask app__ and __scoring app__ onto it.\n",
    "\n",
    "To do so, we'll do the following:\n",
    "1. Build our __flask app__ and __scoring app__ push it to Dockerhub\n",
    "2. Create our dot-yaml files for each of these apps (these dot-yaml files will need to have the proper configuration for the pods to use blobfuse to access our blob storage container). We should end up creating: `flask_app_deployment.json` and `scoring_app_deployment.json`\n",
    "3. Use `kubectl` to make these deployments to our AKS cluster\n",
    "4. Expose the __flask app__ REST endpoint so that it can be accessed externally\n",
    "\n",
    "### Kubernetes Deployment\n",
    "In this notebook, we will deploy our __flask app__ and __scoring app__ on the kubernetes cluster. Since the __flask app__ does not require heavy computation, we will deploy it on one node and reserve the remaining nodes for the __scoring app__ as it will perform the parallel computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and load .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import set_key, get_key, find_dotenv, load_dotenv\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)\n",
    "load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Scoring App Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scoring_app/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile scoring_app/requirements.txt\n",
    "azure==4.0.0\n",
    "torch==0.4.1\n",
    "torchvision==0.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scoring_app/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile scoring_app/Dockerfile\n",
    "\n",
    "FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
    "\n",
    "RUN echo \"deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64 /\" > /etc/apt/sources.list.d/nvidia-ml.list\n",
    "\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "        build-essential \\\n",
    "        ca-certificates \\\n",
    "        cmake \\\n",
    "        curl \\\n",
    "        git \\\n",
    "        nginx \\\n",
    "        supervisor \\\n",
    "        wget && \\\n",
    "        rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "ENV PYTHON_VERSION=3.6\n",
    "RUN curl -o ~/miniconda.sh -O  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh  && \\\n",
    "    chmod +x ~/miniconda.sh && \\\n",
    "    ~/miniconda.sh -b -p /opt/conda && \\\n",
    "    rm ~/miniconda.sh && \\\n",
    "    /opt/conda/bin/conda create -y --name py$PYTHON_VERSION python=$PYTHON_VERSION && \\\n",
    "    /opt/conda/bin/conda clean -ya\n",
    "ENV PATH /opt/conda/envs/py$PYTHON_VERSION/bin:$PATH\n",
    "ENV LD_LIBRARY_PATH /opt/conda/envs/py$PYTHON_VERSION/lib:/usr/local/cuda/lib64/:$LD_LIBRARY_PATH\n",
    "ENV PYTHONPATH /code/:$PYTHONPATH\n",
    "\n",
    "RUN mkdir /app\n",
    "WORKDIR /app\n",
    "ADD process_images_from_queue.py /app\n",
    "ADD style_transfer.py /app\n",
    "ADD main.py /app\n",
    "ADD util.py /app\n",
    "ADD requirements.txt /app\n",
    "ADD azure.py /app\n",
    "\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "CMD [\"python\", \"main.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  35.84kB\n",
      "Step 1/17 : FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
      " ---> 7e8410ba243b\n",
      "Step 2/17 : RUN echo \"deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64 /\" > /etc/apt/sources.list.d/nvidia-ml.list\n",
      " ---> Using cache\n",
      " ---> 2aee8c10151f\n",
      "Step 3/17 : RUN apt-get update && apt-get install -y --no-install-recommends         build-essential         ca-certificates         cmake         curl         git         nginx         supervisor         wget &&         rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> c69b13e821b7\n",
      "Step 4/17 : ENV PYTHON_VERSION=3.6\n",
      " ---> Using cache\n",
      " ---> 9c3490d15c2d\n",
      "Step 5/17 : RUN curl -o ~/miniconda.sh -O  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh  &&     chmod +x ~/miniconda.sh &&     ~/miniconda.sh -b -p /opt/conda &&     rm ~/miniconda.sh &&     /opt/conda/bin/conda create -y --name py$PYTHON_VERSION python=$PYTHON_VERSION &&     /opt/conda/bin/conda clean -ya\n",
      " ---> Using cache\n",
      " ---> 1c03f992fcdc\n",
      "Step 6/17 : ENV PATH /opt/conda/envs/py$PYTHON_VERSION/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> 0657e2c699a2\n",
      "Step 7/17 : ENV LD_LIBRARY_PATH /opt/conda/envs/py$PYTHON_VERSION/lib:/usr/local/cuda/lib64/:$LD_LIBRARY_PATH\n",
      " ---> Using cache\n",
      " ---> 63a9f91c2959\n",
      "Step 8/17 : ENV PYTHONPATH /code/:$PYTHONPATH\n",
      " ---> Using cache\n",
      " ---> 89729243eb37\n",
      "Step 9/17 : RUN mkdir /app\n",
      " ---> Using cache\n",
      " ---> b0591813f73e\n",
      "Step 10/17 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> 9478c90941d9\n",
      "Step 11/17 : ADD process_images_from_queue.py /app\n",
      " ---> Using cache\n",
      " ---> 5cbd91d3b07a\n",
      "Step 12/17 : ADD style_transfer.py /app\n",
      " ---> Using cache\n",
      " ---> 5240c2c86e83\n",
      "Step 13/17 : ADD main.py /app\n",
      " ---> Using cache\n",
      " ---> f06d556d3650\n",
      "Step 14/17 : ADD util.py /app\n",
      " ---> Using cache\n",
      " ---> 6f00348f19a5\n",
      "Step 15/17 : ADD requirements.txt /app\n",
      " ---> Using cache\n",
      " ---> 3376b43dcdf3\n",
      "Step 16/17 : RUN pip install --no-cache-dir -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> 86ddad11c7bd\n",
      "Step 17/17 : CMD [\"python\", \"main.py\"]\n",
      " ---> Using cache\n",
      " ---> 00b96025cc2a\n",
      "Successfully built 00b96025cc2a\n",
      "Successfully tagged oxford_scoring_app:latest\n"
     ]
    }
   ],
   "source": [
    "!sudo docker build -t {get_key(env_path, \"SCORING_IMAGE\")} scoring_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag and push docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/aperture/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!sudo docker login --username pjh177787 --password 'Hans&951022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"{}/{}\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"SCORING_IMAGE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker tag {get_key(env_path, \"SCORING_IMAGE\")} {repo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [docker.io/pjh177787/oxford_scoring_app]\n",
      "\n",
      "\u001b[1B34c46d98: Preparing \n",
      "\u001b[1B112a59d2: Preparing \n",
      "\u001b[1Bb59fe06d: Preparing \n",
      "\u001b[1B93a511e9: Preparing \n",
      "\u001b[1B34dc443b: Preparing \n",
      "\u001b[1B711df71e: Preparing \n",
      "\u001b[1B0c6970e5: Preparing \n",
      "\u001b[1Be82df0c2: Preparing \n",
      "\u001b[1B89b11fc2: Preparing \n",
      "\u001b[1Bb7e6614f: Preparing \n",
      "\u001b[1Bc5838665: Preparing \n",
      "\u001b[1B7ea5d26b: Preparing \n",
      "\u001b[1B7acf624e: Preparing \n",
      "\u001b[1Ba0fe4fdd: Preparing \n",
      "\u001b[1B1c46eb92: Preparing \n",
      "\u001b[1B6e800c43: Preparing \n",
      "\u001b[1Bf22d44f3: Preparing \n",
      "\u001b[1B6f329a25: Preparing \n",
      "\u001b[1B7de5faec: Preparing \n",
      "\u001b[1Ba27b0484: Layer already exists K\u001b[18A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[14A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[13A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[Klatest: digest: sha256:1ee0eb0937c29ab45041fb6b6e3e6fba3f9441b1172410fa8d27c409455bfd8f size: 4507\n"
     ]
    }
   ],
   "source": [
    "!sudo docker push {repo}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Flask App Docker Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our Dockerfile and save it to the directory, `flask_app/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flask_app/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile flask_app/Dockerfile\n",
    "\n",
    "FROM continuumio/miniconda3\n",
    "\n",
    "RUN mkdir /app\n",
    "WORKDIR /app\n",
    "ADD add_images_to_queue.py /app\n",
    "ADD preprocess.py /app\n",
    "ADD postprocess.py /app\n",
    "ADD util.py /app\n",
    "ADD main.py /app\n",
    "ADD azure.py /app\n",
    "\n",
    "RUN conda install -c conda-forge -y ffmpeg\n",
    "RUN pip install azure\n",
    "RUN pip install flask\n",
    "\n",
    "CMD [\"python\", \"main.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  24.06kB\n",
      "Step 1/12 : FROM continuumio/miniconda3\n",
      " ---> 6b5cf97566c3\n",
      "Step 2/12 : RUN mkdir /app\n",
      " ---> Using cache\n",
      " ---> 3e41fbdb3278\n",
      "Step 3/12 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> 032cc5cbe3da\n",
      "Step 4/12 : ADD add_images_to_queue.py /app\n",
      " ---> Using cache\n",
      " ---> a7aad3e80c4e\n",
      "Step 5/12 : ADD preprocess.py /app\n",
      " ---> Using cache\n",
      " ---> 88ec5fb7fcf2\n",
      "Step 6/12 : ADD postprocess.py /app\n",
      " ---> Using cache\n",
      " ---> 796d0a2feade\n",
      "Step 7/12 : ADD util.py /app\n",
      " ---> Using cache\n",
      " ---> 842a56dcdc61\n",
      "Step 8/12 : ADD main.py /app\n",
      " ---> Using cache\n",
      " ---> c01786b74db0\n",
      "Step 9/12 : RUN conda install -c conda-forge -y ffmpeg\n",
      " ---> Using cache\n",
      " ---> 44813df7c13c\n",
      "Step 10/12 : RUN pip install azure\n",
      " ---> Using cache\n",
      " ---> 3f610cf3cffd\n",
      "Step 11/12 : RUN pip install flask\n",
      " ---> Using cache\n",
      " ---> 1391f94ad253\n",
      "Step 12/12 : CMD [\"python\", \"main.py\"]\n",
      " ---> Using cache\n",
      " ---> 8fd611bb40dc\n",
      "Successfully built 8fd611bb40dc\n",
      "Successfully tagged oxford_flask_app:latest\n"
     ]
    }
   ],
   "source": [
    "!sudo docker build -t {get_key(env_path, \"FLASK_IMAGE\")} flask_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag and push."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"{}/{}\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"FLASK_IMAGE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker tag {get_key(env_path, \"FLASK_IMAGE\")} {repo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [docker.io/pjh177787/oxford_flask_app]\n",
      "\n",
      "\u001b[1B46fb0425: Preparing \n",
      "\u001b[1Bdbdc848b: Preparing \n",
      "\u001b[1B671269e9: Preparing \n",
      "\u001b[1B2767c2e6: Preparing \n",
      "\u001b[1Ba5e2b056: Preparing \n",
      "\u001b[1Bfe3428e9: Preparing \n",
      "\u001b[1B55a10f32: Preparing \n",
      "\u001b[2B55a10f32: Waiting g \n",
      "\u001b[1B66549fba: Preparing \n",
      "\u001b[1Bc65c8dc4: Preparing \n",
      "\u001b[1B2f5d7ee9: Preparing \n",
      "\u001b[2B2f5d7ee9: Waiting g \n",
      "\u001b[1B1ff9ade6: Preparing \n",
      "\u001b[2B1ff9ade6: Layer already exists K\u001b[13A\u001b[1K\u001b[K\u001b[11A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[Klatest: digest: sha256:665578e4e83eb869241d779113116ebadc84e0446c8b76bfaf9710db561d479a size: 3249\n"
     ]
    }
   ],
   "source": [
    "!sudo docker push {repo}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our Flask App and Scoring App deployments on AKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to deploy both our aci and aks docker images to the AKS cluster. Since we'll need to set up our gpu and drivers and blobfuse mount point for both deployments, we'll set these up first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_mounts = [\n",
    "#     {\"name\": \"nvidia\", \"mountPath\": \"/usr/local/nvidia\"},\n",
    "#     {\"name\": \"blob\", \"mountPath\": get_key(env_path, \"MOUNT_DIR\")},\n",
    "]\n",
    "\n",
    "resources = {\n",
    "#     \"requests\": {\"alpha.kubernetes.io/nvidia-gpu\": 1},\n",
    "#     \"limits\": {\"alpha.kubernetes.io/nvidia-gpu\": 1},\n",
    "}\n",
    "\n",
    "volumes = [\n",
    "#     {\"name\": \"nvidia\", \"hostPath\": {\"path\": \"/usr/local/nvidia\"}},\n",
    "#     {\n",
    "#         \"name\": \"blob\",\n",
    "#         \"flexVolume\": {\n",
    "#             \"driver\": \"azure/blobfuse\",\n",
    "#             \"readOnly\": False,\n",
    "#             \"secretRef\": {\"name\": \"blobfusecreds\"},\n",
    "#             \"options\": {\n",
    "#                 \"container\": get_key(env_path, \"STORAGE_CONTAINER_NAME\"),\n",
    "#                 \"tmppath\": \"/tmp/blobfuse\",\n",
    "#                 \"mountoptions\": \"--file-cache-timeout-in-seconds=120 --use-https=true\",\n",
    "#             },\n",
    "#         },\n",
    "#     },\n",
    "]\n",
    "\n",
    "env = [\n",
    "    {\n",
    "        \"name\": \"MOUNT_DIR\", \n",
    "        \"value\": get_key(env_path, \"MOUNT_DIR\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"LB_LIBRARY_PATH\",\n",
    "        \"value\": \"$LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"DP_DISABLE_HEALTHCHECKS\", \n",
    "        \"value\": \"xids\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"STORAGE_MODEL_DIR\",\n",
    "        \"value\": get_key(env_path, \"STORAGE_MODEL_DIR\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SUBSCRIPTION_ID\",\n",
    "        \"value\": get_key(env_path, \"SUBSCRIPTION_ID\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"RESOURCE_GROUP\",\n",
    "        \"value\": get_key(env_path, \"RESOURCE_GROUP\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"REGION\",\n",
    "        \"value\": get_key(env_path, \"REGION\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SB_SHARED_ACCESS_KEY_NAME\",\n",
    "        \"value\": get_key(env_path, \"SB_SHARED_ACCESS_KEY_NAME\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SB_SHARED_ACCESS_KEY_VALUE\",\n",
    "        \"value\": get_key(env_path, \"SB_SHARED_ACCESS_KEY_VALUE\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SB_NAMESPACE\",\n",
    "        \"value\": get_key(env_path, \"SB_NAMESPACE\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SB_QUEUE\", \n",
    "        \"value\": get_key(env_path, \"SB_QUEUE\")\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the aks deployment and save it to a `scoring_app_deployment.json` file using the variables set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_app_deployment_json = {\n",
    "    \"apiVersion\": \"apps/v1beta1\",\n",
    "    \"kind\": \"Deployment\",\n",
    "    \"metadata\": {\n",
    "        \"name\": \"scoring-app\", \n",
    "        \"labels\": {\n",
    "            \"purpose\": \"dequeue_messages_and_apply_style_transfer\"\n",
    "        }\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"replicas\": int(get_key(env_path, \"NODE_COUNT\")) - 1,\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"labels\": {\n",
    "                    \"app\": \"scoring-app\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"scoring-app\",\n",
    "                        \"image\": \"{}/{}:latest\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"SCORING_IMAGE\")),\n",
    "                        \"volumeMounts\": volume_mounts,\n",
    "                        \"resources\": resources,\n",
    "                        \"ports\": [{\n",
    "                            \"containerPort\": 433\n",
    "                        }],\n",
    "                        \"env\": env,\n",
    "                    }\n",
    "                ],\n",
    "                \"volumes\": volumes\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(\"scoring_app_deployment.json\", \"w\") as outfile:\n",
    "    json.dump(scoring_app_deployment_json, outfile, indent=4, sort_keys=True)\n",
    "    outfile.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `scoring_app_deployment.json` we created, create our deployment on AKS. This can take a few minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps \"scoring-app\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f scoring_app_deployment.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/scoring-app created\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f scoring_app_deployment.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the flask app deployment and save it to a `flask_app_deployment.json` file using the variables set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "flask_app_deployment_json = {\n",
    "    \"apiVersion\": \"apps/v1beta1\",\n",
    "    \"kind\": \"Deployment\",\n",
    "    \"metadata\": {\n",
    "        \"name\": \"flask-app\", \n",
    "        \"labels\": {\n",
    "            \"purpose\": \"pre_and_post_processing_and_queue_images\"\n",
    "        }\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"replicas\": 1,\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"labels\": {\n",
    "                    \"app\": \"flask-app\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"flask-app\",\n",
    "                        \"image\": \"{}/{}:latest\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"FLASK_IMAGE\")),\n",
    "                        \"volumeMounts\": volume_mounts,\n",
    "                        \"resources\": resources,\n",
    "                        \"ports\": [{\n",
    "                            \"containerPort\": 8080\n",
    "                        }],\n",
    "                        \"env\": env,\n",
    "                    }\n",
    "                ],\n",
    "                \"volumes\": volumes\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(\"flask_app_deployment.json\", \"w\") as outfile:\n",
    "    json.dump(flask_app_deployment_json, outfile, indent=4, sort_keys=True)\n",
    "    outfile.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `flask_app_deployment.json` we created, create our flask app deployment on AKS. This can take a few minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps \"flask-app\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f flask_app_deployment.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/flask-app created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f flask_app_deployment.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These deployments may take a few minutes. You can inspect the state of the pods by running the command: `kubectl get pods`. When the deployment is done, the results may look as follows:\n",
    "```bash\n",
    "NAME                           READY   STATUS              RESTARTS   AGE\n",
    "flask-app-6db66c97ff-x8rq4     1/1     Running             0          78s\n",
    "scoring-app-846dd6bc79-5nm5b   1/1     Running             0          73s\n",
    "scoring-app-846dd6bc79-6qc6k   1/1     Running             0          73s\n",
    "scoring-app-846dd6bc79-8gtsv   1/1     Running             0          73s\n",
    "scoring-app-846dd6bc79-hjsfc   1/1     Running             0          73s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: unable to upgrade connection: container not found (\"scoring-app\")\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl exec scoring-app-7fc7d4cb9d-f7gct -- ls /opt/conda/envs/py3.6/lib/python3.6/site-packages/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app\n",
      "bin\n",
      "boot\n",
      "dev\n",
      "etc\n",
      "home\n",
      "lib\n",
      "lib64\n",
      "media\n",
      "mnt\n",
      "opt\n",
      "proc\n",
      "root\n",
      "run\n",
      "sbin\n",
      "srv\n",
      "sys\n",
      "tmp\n",
      "usr\n",
      "var\n"
     ]
    }
   ],
   "source": [
    "!kubectl exec flask-app-66c4887ff8-wgztf -- ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-15 09:15:16,150 [root:process_images_from_queue.py:34] DEBUG - Start listening to queue 'oxfordqueue' on service bus...\r\n",
      "2019-07-15 09:15:16,150 [root:process_images_from_queue.py:39] DEBUG - Peek queue...\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/urllib3/connection.py\", line 160, in _new_conn\r\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw)\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/urllib3/util/connection.py\", line 57, in create_connection\r\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/socket.py\", line 745, in getaddrinfo\r\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\r\n",
      "socket.gaierror: [Errno -2] Name or service not known\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 603, in urlopen\r\n",
      "    chunked=chunked)\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 344, in _make_request\r\n",
      "    self._validate_conn(conn)\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 843, in _validate_conn\r\n",
      "    conn.connect()\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/urllib3/connection.py\", line 316, in connect\r\n",
      "    conn = self._new_conn()\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/urllib3/connection.py\", line 169, in _new_conn\r\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\r\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x7f4507717f60>: Failed to establish a new connection: [Errno -2] Name or service not known\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\r\n",
      "    timeout=timeout\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 641, in urlopen\r\n",
      "    _stacktrace=sys.exc_info()[2])\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/urllib3/util/retry.py\", line 399, in increment\r\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\r\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='oxfordnames.servicebus.windows.net', port=443): Max retries exceeded with url: /oxfordqueue/messages/head?timeout=30 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f4507717f60>: Failed to establish a new connection: [Errno -2] Name or service not known',))\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"main.py\", line 96, in <module>\r\n",
      "    terminate=args.terminate or os.getenv(\"TERMINATE\"),\r\n",
      "  File \"/app/process_images_from_queue.py\", line 40, in dequeue\r\n",
      "    msg = bus_service.receive_queue_message(queue, peek_lock=True, timeout=30)\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/azure/servicebus/servicebusservice.py\", line 1069, in receive_queue_message\r\n",
      "    return self.peek_lock_queue_message(queue_name, timeout)\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/azure/servicebus/servicebusservice.py\", line 942, in peek_lock_queue_message\r\n",
      "    response = self._perform_request(request)\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/azure/servicebus/servicebusservice.py\", line 1228, in _perform_request\r\n",
      "    resp = self._filter(request)\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/azure/servicebus/_http/httpclient.py\", line 181, in perform_request\r\n",
      "    self.send_request_body(connection, request.body)\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/azure/servicebus/_http/httpclient.py\", line 145, in send_request_body\r\n",
      "    connection.send(None)\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/azure/servicebus/_http/requestsclient.py\", line 81, in send\r\n",
      "    self.response = self.session.request(self.method, self.uri, data=request_body, headers=self.headers, timeout=self.timeout)\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\r\n",
      "    resp = self.send(prep, **send_kwargs)\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\r\n",
      "    r = adapter.send(request, **kwargs)\r\n",
      "  File \"/opt/conda/envs/py3.6/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\r\n",
      "    raise ConnectionError(e, request=request)\r\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='oxfordnames.servicebus.windows.net', port=443): Max retries exceeded with url: /oxfordqueue/messages/head?timeout=30 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f4507717f60>: Failed to establish a new connection: [Errno -2] Name or service not known',))\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl logs scoring-app-7fc7d4cb9d-f7gct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:           flask-app-66c4887ff8-wgztf\n",
      "Namespace:      default\n",
      "Priority:       0\n",
      "Node:           aks-nodepool1-80042525-2/10.240.0.6\n",
      "Start Time:     Mon, 15 Jul 2019 09:10:55 +0000\n",
      "Labels:         app=flask-app\n",
      "                pod-template-hash=66c4887ff8\n",
      "Annotations:    <none>\n",
      "Status:         Running\n",
      "IP:             10.244.4.8\n",
      "Controlled By:  ReplicaSet/flask-app-66c4887ff8\n",
      "Containers:\n",
      "  flask-app:\n",
      "    Container ID:   docker://e4d37554f27a8d3647f2a0cccff0225b2c0a5d9745961e5c9ec69e5815717b0a\n",
      "    Image:          pjh177787/oxford_flask_app:latest\n",
      "    Image ID:       docker-pullable://pjh177787/oxford_flask_app@sha256:665578e4e83eb869241d779113116ebadc84e0446c8b76bfaf9710db561d479a\n",
      "    Port:           8080/TCP\n",
      "    Host Port:      0/TCP\n",
      "    State:          Running\n",
      "      Started:      Mon, 15 Jul 2019 09:11:01 +0000\n",
      "    Ready:          True\n",
      "    Restart Count:  0\n",
      "    Environment:\n",
      "      MOUNT_DIR:                     /data\n",
      "      LB_LIBRARY_PATH:               $LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\n",
      "      DP_DISABLE_HEALTHCHECKS:       xids\n",
      "      STORAGE_MODEL_DIR:             models\n",
      "      SUBSCRIPTION_ID:               43f94930-ca31-4ddc-91c2-2f1be4f0e8f3\n",
      "      RESOURCE_GROUP:                oxford\n",
      "      REGION:                        chinaeast2\n",
      "      SB_SHARED_ACCESS_KEY_NAME:     RootManageSharedAccessKey\n",
      "      SB_SHARED_ACCESS_KEY_VALUE:    Ap2qhvyHeoIjvq1GjwkVP3/Xn5J1epdB1bXZgbHfmwA=\n",
      "      SB_NAMESPACE:                  oxfordnames\n",
      "      SB_QUEUE:                      oxfordqueue\n",
      "      KUBERNETES_PORT_443_TCP_ADDR:  oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn\n",
      "      KUBERNETES_PORT:               tcp://oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\n",
      "      KUBERNETES_PORT_443_TCP:       tcp://oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\n",
      "      KUBERNETES_SERVICE_HOST:       oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn\n",
      "    Mounts:\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from default-token-vg5wp (ro)\n",
      "Conditions:\n",
      "  Type              Status\n",
      "  Initialized       True \n",
      "  Ready             True \n",
      "  ContainersReady   True \n",
      "  PodScheduled      True \n",
      "Volumes:\n",
      "  default-token-vg5wp:\n",
      "    Type:        Secret (a volume populated by a Secret)\n",
      "    SecretName:  default-token-vg5wp\n",
      "    Optional:    false\n",
      "QoS Class:       BestEffort\n",
      "Node-Selectors:  <none>\n",
      "Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n",
      "                 node.kubernetes.io/unreachable:NoExecute for 300s\n",
      "Events:\n",
      "  Type    Reason     Age    From                               Message\n",
      "  ----    ------     ----   ----                               -------\n",
      "  Normal  Scheduled  2m25s  default-scheduler                  Successfully assigned default/flask-app-66c4887ff8-wgztf to aks-nodepool1-80042525-2\n",
      "  Normal  Pulling    2m24s  kubelet, aks-nodepool1-80042525-2  pulling image \"pjh177787/oxford_flask_app:latest\"\n",
      "  Normal  Pulled     2m20s  kubelet, aks-nodepool1-80042525-2  Successfully pulled image \"pjh177787/oxford_flask_app:latest\"\n",
      "  Normal  Created    2m19s  kubelet, aks-nodepool1-80042525-2  Created container\n",
      "  Normal  Started    2m19s  kubelet, aks-nodepool1-80042525-2  Started container\n",
      "\n",
      "\n",
      "Name:           scoring-app-7fc7d4cb9d-f7gct\n",
      "Namespace:      default\n",
      "Priority:       0\n",
      "Node:           aks-nodepool1-80042525-4/10.240.0.4\n",
      "Start Time:     Mon, 15 Jul 2019 09:10:54 +0000\n",
      "Labels:         app=scoring-app\n",
      "                pod-template-hash=7fc7d4cb9d\n",
      "Annotations:    <none>\n",
      "Status:         Running\n",
      "IP:             10.244.2.5\n",
      "Controlled By:  ReplicaSet/scoring-app-7fc7d4cb9d\n",
      "Containers:\n",
      "  scoring-app:\n",
      "    Container ID:   docker://b0e7c2f203c87067fbc77ceddedae5496629c669265038690e27f5fe76af1a0e\n",
      "    Image:          pjh177787/oxford_scoring_app:latest\n",
      "    Image ID:       docker-pullable://pjh177787/oxford_scoring_app@sha256:1ee0eb0937c29ab45041fb6b6e3e6fba3f9441b1172410fa8d27c409455bfd8f\n",
      "    Port:           433/TCP\n",
      "    Host Port:      0/TCP\n",
      "    State:          Waiting\n",
      "      Reason:       CrashLoopBackOff\n",
      "    Last State:     Terminated\n",
      "      Reason:       Error\n",
      "      Exit Code:    1\n",
      "      Started:      Mon, 15 Jul 2019 09:12:47 +0000\n",
      "      Finished:     Mon, 15 Jul 2019 09:12:47 +0000\n",
      "    Ready:          False\n",
      "    Restart Count:  4\n",
      "    Environment:\n",
      "      MOUNT_DIR:                     /data\n",
      "      LB_LIBRARY_PATH:               $LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\n",
      "      DP_DISABLE_HEALTHCHECKS:       xids\n",
      "      STORAGE_MODEL_DIR:             models\n",
      "      SUBSCRIPTION_ID:               43f94930-ca31-4ddc-91c2-2f1be4f0e8f3\n",
      "      RESOURCE_GROUP:                oxford\n",
      "      REGION:                        chinaeast2\n",
      "      SB_SHARED_ACCESS_KEY_NAME:     RootManageSharedAccessKey\n",
      "      SB_SHARED_ACCESS_KEY_VALUE:    Ap2qhvyHeoIjvq1GjwkVP3/Xn5J1epdB1bXZgbHfmwA=\n",
      "      SB_NAMESPACE:                  oxfordnames\n",
      "      SB_QUEUE:                      oxfordqueue\n",
      "      KUBERNETES_PORT_443_TCP_ADDR:  oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn\n",
      "      KUBERNETES_PORT:               tcp://oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\n",
      "      KUBERNETES_PORT_443_TCP:       tcp://oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\n",
      "      KUBERNETES_SERVICE_HOST:       oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn\n",
      "    Mounts:\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from default-token-vg5wp (ro)\n",
      "Conditions:\n",
      "  Type              Status\n",
      "  Initialized       True \n",
      "  Ready             False \n",
      "  ContainersReady   False \n",
      "  PodScheduled      True \n",
      "Volumes:\n",
      "  default-token-vg5wp:\n",
      "    Type:        Secret (a volume populated by a Secret)\n",
      "    SecretName:  default-token-vg5wp\n",
      "    Optional:    false\n",
      "QoS Class:       BestEffort\n",
      "Node-Selectors:  <none>\n",
      "Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n",
      "                 node.kubernetes.io/unreachable:NoExecute for 300s\n",
      "Events:\n",
      "  Type     Reason     Age                  From                               Message\n",
      "  ----     ------     ----                 ----                               -------\n",
      "  Normal   Scheduled  2m26s                default-scheduler                  Successfully assigned default/scoring-app-7fc7d4cb9d-f7gct to aks-nodepool1-80042525-4\n",
      "  Normal   Pulled     87s (x4 over 2m22s)  kubelet, aks-nodepool1-80042525-4  Successfully pulled image \"pjh177787/oxford_scoring_app:latest\"\n",
      "  Normal   Created    87s (x4 over 2m22s)  kubelet, aks-nodepool1-80042525-4  Created container\n",
      "  Normal   Started    86s (x4 over 2m22s)  kubelet, aks-nodepool1-80042525-4  Started container\n",
      "  Warning  BackOff    48s (x8 over 2m16s)  kubelet, aks-nodepool1-80042525-4  Back-off restarting failed container\n",
      "  Normal   Pulling    37s (x5 over 2m25s)  kubelet, aks-nodepool1-80042525-4  pulling image \"pjh177787/oxford_scoring_app:latest\"\n",
      "\n",
      "\n",
      "Name:           scoring-app-7fc7d4cb9d-krlgj\n",
      "Namespace:      default\n",
      "Priority:       0\n",
      "Node:           aks-nodepool1-80042525-0/10.240.0.7\n",
      "Start Time:     Mon, 15 Jul 2019 09:10:54 +0000\n",
      "Labels:         app=scoring-app\n",
      "                pod-template-hash=7fc7d4cb9d\n",
      "Annotations:    <none>\n",
      "Status:         Running\n",
      "IP:             10.244.3.6\n",
      "Controlled By:  ReplicaSet/scoring-app-7fc7d4cb9d\n",
      "Containers:\n",
      "  scoring-app:\n",
      "    Container ID:   docker://4e6b9d473eb494362f997def0fc4fd2f4ee00c3aae38ff3b71cdbb02c41caa55\n",
      "    Image:          pjh177787/oxford_scoring_app:latest\n",
      "    Image ID:       docker-pullable://pjh177787/oxford_scoring_app@sha256:1ee0eb0937c29ab45041fb6b6e3e6fba3f9441b1172410fa8d27c409455bfd8f\n",
      "    Port:           433/TCP\n",
      "    Host Port:      0/TCP\n",
      "    State:          Waiting\n",
      "      Reason:       CrashLoopBackOff\n",
      "    Last State:     Terminated\n",
      "      Reason:       Error\n",
      "      Exit Code:    1\n",
      "      Started:      Mon, 15 Jul 2019 09:12:47 +0000\n",
      "      Finished:     Mon, 15 Jul 2019 09:12:48 +0000\n",
      "    Ready:          False\n",
      "    Restart Count:  4\n",
      "    Environment:\n",
      "      MOUNT_DIR:                     /data\n",
      "      LB_LIBRARY_PATH:               $LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\n",
      "      DP_DISABLE_HEALTHCHECKS:       xids\n",
      "      STORAGE_MODEL_DIR:             models\n",
      "      SUBSCRIPTION_ID:               43f94930-ca31-4ddc-91c2-2f1be4f0e8f3\n",
      "      RESOURCE_GROUP:                oxford\n",
      "      REGION:                        chinaeast2\n",
      "      SB_SHARED_ACCESS_KEY_NAME:     RootManageSharedAccessKey\n",
      "      SB_SHARED_ACCESS_KEY_VALUE:    Ap2qhvyHeoIjvq1GjwkVP3/Xn5J1epdB1bXZgbHfmwA=\n",
      "      SB_NAMESPACE:                  oxfordnames\n",
      "      SB_QUEUE:                      oxfordqueue\n",
      "      KUBERNETES_PORT_443_TCP_ADDR:  oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn\n",
      "      KUBERNETES_PORT:               tcp://oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\n",
      "      KUBERNETES_PORT_443_TCP:       tcp://oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\n",
      "      KUBERNETES_SERVICE_HOST:       oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn\n",
      "    Mounts:\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from default-token-vg5wp (ro)\n",
      "Conditions:\n",
      "  Type              Status\n",
      "  Initialized       True \n",
      "  Ready             False \n",
      "  ContainersReady   False \n",
      "  PodScheduled      True \n",
      "Volumes:\n",
      "  default-token-vg5wp:\n",
      "    Type:        Secret (a volume populated by a Secret)\n",
      "    SecretName:  default-token-vg5wp\n",
      "    Optional:    false\n",
      "QoS Class:       BestEffort\n",
      "Node-Selectors:  <none>\n",
      "Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n",
      "                 node.kubernetes.io/unreachable:NoExecute for 300s\n",
      "Events:\n",
      "  Type     Reason     Age                  From                               Message\n",
      "  ----     ------     ----                 ----                               -------\n",
      "  Normal   Scheduled  2m26s                default-scheduler                  Successfully assigned default/scoring-app-7fc7d4cb9d-krlgj to aks-nodepool1-80042525-0\n",
      "  Normal   Pulled     87s (x4 over 2m22s)  kubelet, aks-nodepool1-80042525-0  Successfully pulled image \"pjh177787/oxford_scoring_app:latest\"\n",
      "  Normal   Created    87s (x4 over 2m22s)  kubelet, aks-nodepool1-80042525-0  Created container\n",
      "  Normal   Started    87s (x4 over 2m22s)  kubelet, aks-nodepool1-80042525-0  Started container\n",
      "  Warning  BackOff    49s (x8 over 2m16s)  kubelet, aks-nodepool1-80042525-0  Back-off restarting failed container\n",
      "  Normal   Pulling    38s (x5 over 2m25s)  kubelet, aks-nodepool1-80042525-0  pulling image \"pjh177787/oxford_scoring_app:latest\"\n",
      "\n",
      "\n",
      "Name:           scoring-app-7fc7d4cb9d-kx8zm\n",
      "Namespace:      default\n",
      "Priority:       0\n",
      "Node:           aks-nodepool1-80042525-2/10.240.0.6\n",
      "Start Time:     Mon, 15 Jul 2019 09:10:54 +0000\n",
      "Labels:         app=scoring-app\n",
      "                pod-template-hash=7fc7d4cb9d\n",
      "Annotations:    <none>\n",
      "Status:         Running\n",
      "IP:             10.244.4.7\n",
      "Controlled By:  ReplicaSet/scoring-app-7fc7d4cb9d\n",
      "Containers:\n",
      "  scoring-app:\n",
      "    Container ID:   docker://a4ed9c2ad6ac9a06fbb5aa905b8540238f932e12b4b56047e238ab93f86f024b\n",
      "    Image:          pjh177787/oxford_scoring_app:latest\n",
      "    Image ID:       docker-pullable://pjh177787/oxford_scoring_app@sha256:1ee0eb0937c29ab45041fb6b6e3e6fba3f9441b1172410fa8d27c409455bfd8f\n",
      "    Port:           433/TCP\n",
      "    Host Port:      0/TCP\n",
      "    State:          Waiting\n",
      "      Reason:       CrashLoopBackOff\n",
      "    Last State:     Terminated\n",
      "      Reason:       Error\n",
      "      Exit Code:    1\n",
      "      Started:      Mon, 15 Jul 2019 09:12:47 +0000\n",
      "      Finished:     Mon, 15 Jul 2019 09:12:48 +0000\n",
      "    Ready:          False\n",
      "    Restart Count:  4\n",
      "    Environment:\n",
      "      MOUNT_DIR:                     /data\n",
      "      LB_LIBRARY_PATH:               $LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\n",
      "      DP_DISABLE_HEALTHCHECKS:       xids\n",
      "      STORAGE_MODEL_DIR:             models\n",
      "      SUBSCRIPTION_ID:               43f94930-ca31-4ddc-91c2-2f1be4f0e8f3\n",
      "      RESOURCE_GROUP:                oxford\n",
      "      REGION:                        chinaeast2\n",
      "      SB_SHARED_ACCESS_KEY_NAME:     RootManageSharedAccessKey\n",
      "      SB_SHARED_ACCESS_KEY_VALUE:    Ap2qhvyHeoIjvq1GjwkVP3/Xn5J1epdB1bXZgbHfmwA=\n",
      "      SB_NAMESPACE:                  oxfordnames\n",
      "      SB_QUEUE:                      oxfordqueue\n",
      "      KUBERNETES_PORT_443_TCP_ADDR:  oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn\n",
      "      KUBERNETES_PORT:               tcp://oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\n",
      "      KUBERNETES_PORT_443_TCP:       tcp://oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\n",
      "      KUBERNETES_SERVICE_HOST:       oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn\n",
      "    Mounts:\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from default-token-vg5wp (ro)\n",
      "Conditions:\n",
      "  Type              Status\n",
      "  Initialized       True \n",
      "  Ready             False \n",
      "  ContainersReady   False \n",
      "  PodScheduled      True \n",
      "Volumes:\n",
      "  default-token-vg5wp:\n",
      "    Type:        Secret (a volume populated by a Secret)\n",
      "    SecretName:  default-token-vg5wp\n",
      "    Optional:    false\n",
      "QoS Class:       BestEffort\n",
      "Node-Selectors:  <none>\n",
      "Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n",
      "                 node.kubernetes.io/unreachable:NoExecute for 300s\n",
      "Events:\n",
      "  Type     Reason     Age                  From                               Message\n",
      "  ----     ------     ----                 ----                               -------\n",
      "  Normal   Scheduled  2m26s                default-scheduler                  Successfully assigned default/scoring-app-7fc7d4cb9d-kx8zm to aks-nodepool1-80042525-2\n",
      "  Normal   Created    83s (x4 over 2m22s)  kubelet, aks-nodepool1-80042525-2  Created container\n",
      "  Normal   Started    82s (x4 over 2m22s)  kubelet, aks-nodepool1-80042525-2  Started container\n",
      "  Warning  BackOff    51s (x7 over 2m12s)  kubelet, aks-nodepool1-80042525-2  Back-off restarting failed container\n",
      "  Normal   Pulling    39s (x5 over 2m25s)  kubelet, aks-nodepool1-80042525-2  pulling image \"pjh177787/oxford_scoring_app:latest\"\n",
      "  Normal   Pulled     33s (x5 over 2m22s)  kubelet, aks-nodepool1-80042525-2  Successfully pulled image \"pjh177787/oxford_scoring_app:latest\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "Name:           scoring-app-7fc7d4cb9d-mm449\r\n",
      "Namespace:      default\r\n",
      "Priority:       0\r\n",
      "Node:           aks-nodepool1-80042525-3/10.240.0.5\r\n",
      "Start Time:     Mon, 15 Jul 2019 09:10:54 +0000\r\n",
      "Labels:         app=scoring-app\r\n",
      "                pod-template-hash=7fc7d4cb9d\r\n",
      "Annotations:    <none>\r\n",
      "Status:         Running\r\n",
      "IP:             10.244.1.5\r\n",
      "Controlled By:  ReplicaSet/scoring-app-7fc7d4cb9d\r\n",
      "Containers:\r\n",
      "  scoring-app:\r\n",
      "    Container ID:   docker://dc5399d8fecf9d6e3a059bb1e318cd50b4aae44984247b7b756f4bbbd0b7d368\r\n",
      "    Image:          pjh177787/oxford_scoring_app:latest\r\n",
      "    Image ID:       docker-pullable://pjh177787/oxford_scoring_app@sha256:1ee0eb0937c29ab45041fb6b6e3e6fba3f9441b1172410fa8d27c409455bfd8f\r\n",
      "    Port:           433/TCP\r\n",
      "    Host Port:      0/TCP\r\n",
      "    State:          Waiting\r\n",
      "      Reason:       CrashLoopBackOff\r\n",
      "    Last State:     Terminated\r\n",
      "      Reason:       Error\r\n",
      "      Exit Code:    1\r\n",
      "      Started:      Mon, 15 Jul 2019 09:12:49 +0000\r\n",
      "      Finished:     Mon, 15 Jul 2019 09:12:49 +0000\r\n",
      "    Ready:          False\r\n",
      "    Restart Count:  4\r\n",
      "    Environment:\r\n",
      "      MOUNT_DIR:                     /data\r\n",
      "      LB_LIBRARY_PATH:               $LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\r\n",
      "      DP_DISABLE_HEALTHCHECKS:       xids\r\n",
      "      STORAGE_MODEL_DIR:             models\r\n",
      "      SUBSCRIPTION_ID:               43f94930-ca31-4ddc-91c2-2f1be4f0e8f3\r\n",
      "      RESOURCE_GROUP:                oxford\r\n",
      "      REGION:                        chinaeast2\r\n",
      "      SB_SHARED_ACCESS_KEY_NAME:     RootManageSharedAccessKey\r\n",
      "      SB_SHARED_ACCESS_KEY_VALUE:    Ap2qhvyHeoIjvq1GjwkVP3/Xn5J1epdB1bXZgbHfmwA=\r\n",
      "      SB_NAMESPACE:                  oxfordnames\r\n",
      "      SB_QUEUE:                      oxfordqueue\r\n",
      "      KUBERNETES_PORT_443_TCP_ADDR:  oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn\r\n",
      "      KUBERNETES_PORT:               tcp://oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\r\n",
      "      KUBERNETES_PORT_443_TCP:       tcp://oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn:443\r\n",
      "      KUBERNETES_SERVICE_HOST:       oxfordclus-oxford-43f949-c6cc4a17.hcp.chinaeast2.cx.prod.service.azk8s.cn\r\n",
      "    Mounts:\r\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from default-token-vg5wp (ro)\r\n",
      "Conditions:\r\n",
      "  Type              Status\r\n",
      "  Initialized       True \r\n",
      "  Ready             False \r\n",
      "  ContainersReady   False \r\n",
      "  PodScheduled      True \r\n",
      "Volumes:\r\n",
      "  default-token-vg5wp:\r\n",
      "    Type:        Secret (a volume populated by a Secret)\r\n",
      "    SecretName:  default-token-vg5wp\r\n",
      "    Optional:    false\r\n",
      "QoS Class:       BestEffort\r\n",
      "Node-Selectors:  <none>\r\n",
      "Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\r\n",
      "                 node.kubernetes.io/unreachable:NoExecute for 300s\r\n",
      "Events:\r\n",
      "  Type     Reason     Age                  From                               Message\r\n",
      "  ----     ------     ----                 ----                               -------\r\n",
      "  Normal   Scheduled  2m26s                default-scheduler                  Successfully assigned default/scoring-app-7fc7d4cb9d-mm449 to aks-nodepool1-80042525-3\r\n",
      "  Normal   Pulled     89s (x4 over 2m23s)  kubelet, aks-nodepool1-80042525-3  Successfully pulled image \"pjh177787/oxford_scoring_app:latest\"\r\n",
      "  Normal   Created    89s (x4 over 2m23s)  kubelet, aks-nodepool1-80042525-3  Created container\r\n",
      "  Normal   Started    89s (x4 over 2m22s)  kubelet, aks-nodepool1-80042525-3  Started container\r\n",
      "  Warning  BackOff    51s (x8 over 2m17s)  kubelet, aks-nodepool1-80042525-3  Back-off restarting failed container\r\n",
      "  Normal   Pulling    39s (x5 over 2m25s)  kubelet, aks-nodepool1-80042525-3  pulling image \"pjh177787/oxford_scoring_app:latest\"\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expose the flask-app in the kubernetes cluster. This will open a public endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/flask-app exposed\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl expose deployment flask-app --type=\"LoadBalancer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `!watch kubectl get services` and wait until the external ip goes from pending to being realized. It can take some time.\n",
    "\n",
    "NOTE: If the following command is run without the external ip being realized, an error will be thrown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-6d828295755d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexternal_ip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kubectl get services -o=jsonpath={.items[*].status.loadBalancer.ingress[0].ip}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexternal_ip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexternal_ip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "external_ip = !kubectl get services -o=jsonpath={.items[*].status.loadBalancer.ingress[0].ip}\n",
    "external_ip = external_ip[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we'll use the `external_ip` later on, save it to the dot-env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "strip_out"
    ]
   },
   "outputs": [],
   "source": [
    "set_key(env_path, \"AKS_EXTERNAL_IP\", external_ip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test that the deployment works end-to-end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the name of the new test video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_video_name = \"aks_test_orangutan.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a copy the old `orangutan.mp4` video but named with the `<new_video_name>`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp data/orangutan.mp4 data/{new_video_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `curl` to hit the endpoint of the kubernetes cluster we just deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl {external_ip}\":8080/process?video_name=\"{new_video_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect your kubernetes cluster to see that the process is running. You can use the commands below to do so. Alternatively, you can also inspect the blob storage container to see that the images are being created.\n",
    "\n",
    "When the video completes, you can play the video file directly from your mounted blob container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<video width=\"320\" height=\"240\" controls>\n",
    "  <source src=\"data/aks_test_orangutan/aks_test_orangutan_processed.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Kubectl usage\n",
    "You can use kubectl to perform basic monitoring. Use the following commands:\n",
    "```bash\n",
    "# monitor pods\n",
    "!kubectl get pods\n",
    "\n",
    "# print logs from a pod (<pod-name> can be found when calling 'get pods')\n",
    "!kubectl logs <pod-name>\n",
    "\n",
    "# check all services running on the cluster\n",
    "!kubectl get services\n",
    "\n",
    "# delete a service\n",
    "!kubectl delete services <service-name>\n",
    "\n",
    "# delete a deployment\n",
    "!kubectl delete -f scoring_app_deployment.json\n",
    "!kubectl delete -f flask_app_deployment.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor in kubernetes dashboard\n",
    "You can use the Kubernetes dashboard to monitor the cluster using the following commands:\n",
    "\n",
    "```bash\n",
    "# use the kube_dashboard_access.yaml to create a deployment\n",
    "!kubectl create -f kube_dashboard_access.yaml\n",
    "\n",
    "# use this command to browse\n",
    "!az aks browse -n {get_key(env_path, \"AKS_CLUSTER\")} -g {get_key(env_path, \"RESOURCE_GROUP\")}\n",
    "```\n",
    "\n",
    "If you're not able to access the dashboard, follow the instructions [here](https://blog.tekspace.io/kubernetes-dashboard-remote-access/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional commands for AKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale your AKS cluster:\n",
    "\n",
    "```bash \n",
    "!az aks scale \\\n",
    "    --name {get_key(env_path, \"AKS_CLUSTER\")} \\\n",
    "    --resource-group {get_key(env_path, \"RESOURCE_GROUP\")} \\\n",
    "    --node-count 10\n",
    "```\n",
    "\n",
    "Scale your deployment:\n",
    "```bash\n",
    "!kubectl scale deployment.apps/aks-app --replicas=10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue to the next [notebook](/notebooks/05_deploy_logic_app.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bc_aks] *",
   "language": "python",
   "name": "conda-env-bc_aks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
